{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3752ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdiffeq in /srv/conda/envs/notebook/lib/python3.12/site-packages (0.2.5)\n",
      "Requirement already satisfied: torch>=1.5.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torchdiffeq) (2.5.1.post303)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torchdiffeq) (1.16.0)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from scipy>=1.4.0->torchdiffeq) (2.2.6)\n",
      "Requirement already satisfied: filelock in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (4.14.1)\n",
      "Requirement already satisfied: networkx in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.5)\n",
      "Requirement already satisfied: jinja2 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (80.9.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /srv/conda/envs/notebook/lib/python3.12/site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46d87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torchdiffeq import odeint_adjoint\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf58ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Masked data - Min: 0.00e+00, Max: 6.54e+08\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_dir = Path(\"./data\")\n",
    "test_data = np.load(data_dir / \"test_arr.npz\")\n",
    "data_array = test_data['data']  # shape (time, features, ensemble, ics)\n",
    "mask_array = test_data['mask']  # same shape as data_array\n",
    "\n",
    "# Apply masking\n",
    "data_masked = np.ma.MaskedArray(data_array, mask=mask_array)\n",
    "print(f\"\\nMasked data - Min: {data_masked.min():.2e}, Max: {data_masked.max():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fd4235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ICs: 100\n",
      "Train ICs: 80, Val ICs: 20\n"
     ]
    }
   ],
   "source": [
    "# Use 80% of the data for training\n",
    "n_ics_total = data_array.shape[2]\n",
    "n_ics_train = int(0.8 * n_ics_total)\n",
    "print(f\"Total ICs: {n_ics_total}\")\n",
    "\n",
    "# Split: first 80% for train, rest for validation\n",
    "train_indices = np.arange(n_ics_train)\n",
    "val_indices = np.arange(n_ics_train, n_ics_total)\n",
    "print(f\"Train ICs: {len(train_indices)}, Val ICs: {len(val_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df0aef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moment indices: [1, 2, 3, 4]\n",
      "Environmental parameter indices: [14, 15, 16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble mean shape: (3599, 18, 100)\n"
     ]
    }
   ],
   "source": [
    "# Extract features: moments [1-4] and environmental params [14-16]\n",
    "moment_indices = [1, 2, 3, 4]  # qc, nc, qr, nr\n",
    "env_indices = [14, 15, 16]  # q_w0, r_0, Î½\n",
    "\n",
    "print(f\"Moment indices: {moment_indices}\")\n",
    "print(f\"Environmental parameter indices: {env_indices}\")\n",
    "\n",
    "# Compute ensemble mean (average over the 100 instances dimension)\n",
    "data_mean = data_masked.mean(axis=3)  # Shape: (time, features, ics)\n",
    "print(f\"\\nEnsemble mean shape: {data_mean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b6f7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training trajectories: 80\n",
      "Number of validation trajectories: 20\n",
      "\n",
      "Example trajectory lengths (train):\n",
      "  Trajectory 0: 130 timesteps\n",
      "  Trajectory 1: 779 timesteps\n",
      "  Trajectory 2: 324 timesteps\n",
      "  Trajectory 3: 149 timesteps\n",
      "  Trajectory 4: 59 timesteps\n"
     ]
    }
   ],
   "source": [
    "# Create trajectories with proper masking\n",
    "def extract_trajectories(data_mean, ic_indices, moment_indices, env_indices):\n",
    "    \"\"\"\n",
    "    Extract valid trajectories for given IC indices.\n",
    "    Returns list of dicts with 'moments', 'env_params', 'length'\n",
    "    \"\"\"\n",
    "    trajectories = []\n",
    "    \n",
    "    for ic_idx in ic_indices:\n",
    "        # Extract moments and env params for this IC\n",
    "        moments = data_mean[:, moment_indices, ic_idx]  # (time, 4)\n",
    "        env_params = data_mean[0, env_indices, ic_idx]  # (3,) - constant across time\n",
    "        \n",
    "        # Find valid timesteps (check first moment)\n",
    "        valid_mask = ~moments[:, 0].mask\n",
    "        n_valid = valid_mask.sum()\n",
    "        \n",
    "        if n_valid > 1:  # Need at least 2 timesteps for derivatives\n",
    "            # Extract only valid data\n",
    "            moments_valid = moments[valid_mask].data  # (n_valid, 4)\n",
    "            env_params_valid = env_params.data  # (3,)\n",
    "            \n",
    "            trajectories.append({\n",
    "                'moments': moments_valid,\n",
    "                'env_params': env_params_valid,\n",
    "                'length': n_valid,\n",
    "                'ic_idx': ic_idx\n",
    "            })\n",
    "    \n",
    "    return trajectories\n",
    "\n",
    "train_trajectories = extract_trajectories(data_mean, train_indices, moment_indices, env_indices)\n",
    "val_trajectories = extract_trajectories(data_mean, val_indices, moment_indices, env_indices)\n",
    "\n",
    "print(f\"\\nNumber of training trajectories: {len(train_trajectories)}\")\n",
    "print(f\"Number of validation trajectories: {len(val_trajectories)}\")\n",
    "print(f\"\\nExample trajectory lengths (train):\")\n",
    "for i in range(min(5, len(train_trajectories))):\n",
    "    print(f\"  Trajectory {i}: {train_trajectories[i]['length']} timesteps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa636d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example log-moment range: [-23.03, 19.21]\n"
     ]
    }
   ],
   "source": [
    "# Apply log-transform to moments\n",
    "epsilon = 1e-10\n",
    "\n",
    "def log_transform_moments(moments):\n",
    "    \"\"\"Apply log transform to moments.\"\"\"\n",
    "    return np.log(moments + epsilon)\n",
    "\n",
    "def inverse_log_transform_moments(log_moments):\n",
    "    \"\"\"Inverse log transform.\"\"\"\n",
    "    return np.exp(log_moments) - epsilon\n",
    "\n",
    "# Transform all trajectories\n",
    "for traj in train_trajectories:\n",
    "    traj['log_moments'] = log_transform_moments(traj['moments'])\n",
    "\n",
    "for traj in val_trajectories:\n",
    "    traj['log_moments'] = log_transform_moments(traj['moments'])\n",
    "\n",
    "print(f\"Example log-moment range: [{train_trajectories[0]['log_moments'].min():.2f}, {train_trajectories[0]['log_moments'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7cfb4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environmental parameter statistics (before scaling):\n",
      "  Mean: [8.84999941e-04 1.19000000e-05 2.10625000e+00]\n",
      "  Std: [4.63707871e-04 2.02854569e-06 1.19030918e+00]\n",
      "\n",
      "Environmental parameter statistics (after scaling):\n",
      "  Mean: [ 8.32667268e-16  4.87387908e-15 -1.74686654e-16]\n",
      "  Std: [1. 1. 1.]\n",
      "\n",
      "Scaler saved to data/env_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Fit StandardScaler on environmental parameters (training data only)\n",
    "env_params_train = np.array([traj['env_params'] for traj in train_trajectories])\n",
    "env_scaler = StandardScaler()\n",
    "env_scaler.fit(env_params_train)\n",
    "\n",
    "print(f\"\\nEnvironmental parameter statistics (before scaling):\")\n",
    "print(f\"  Mean: {env_params_train.mean(axis=0)}\")\n",
    "print(f\"  Std: {env_params_train.std(axis=0)}\")\n",
    "\n",
    "# Apply scaling to all trajectories\n",
    "for traj in train_trajectories:\n",
    "    traj['env_params_scaled'] = env_scaler.transform(traj['env_params'].reshape(1, -1)).flatten()\n",
    "\n",
    "for traj in val_trajectories:\n",
    "    traj['env_params_scaled'] = env_scaler.transform(traj['env_params'].reshape(1, -1)).flatten()\n",
    "\n",
    "print(f\"\\nEnvironmental parameter statistics (after scaling):\")\n",
    "env_params_scaled_train = np.array([traj['env_params_scaled'] for traj in train_trajectories])\n",
    "print(f\"  Mean: {env_params_scaled_train.mean(axis=0)}\")\n",
    "print(f\"  Std: {env_params_scaled_train.std(axis=0)}\")\n",
    "\n",
    "# Save scaler for later use\n",
    "with open(data_dir / 'env_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(env_scaler, f)\n",
    "print(\"\\nScaler saved to data/env_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4919aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train and val trajectories for later use\n",
    "with open(data_dir / \"train_trajectories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_trajectories, f)\n",
    "\n",
    "with open(data_dir / \"val_trajectories.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_trajectories, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
